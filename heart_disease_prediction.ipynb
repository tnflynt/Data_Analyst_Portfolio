{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart disease prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnflynt/Data_Analyst_Portfolio/blob/main/Heart_disease_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oP3P345nfhp"
      },
      "source": [
        "# Heart disease prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The objective of this exercise is to buid a machine learning model to accurately predict whether a patient has a heart disease or not (i.e. Outcome = 1 ~ is at risk of heart disease and Outcome = 0 ~ is no risk of heart disease)"
      ],
      "metadata": {
        "id": "slhQpWq2KkqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up PySpark and creating a Spark Session**"
      ],
      "metadata": {
        "id": "ssYMAJD9Kk0U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ndvgw7myFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a89f008-84f2-4ae6-e73e-268b6f8082c2"
      },
      "source": [
        "!sudo apt update\n",
        "!sudo apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "15 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsVYVg0fn7Go"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8UlSSauoCZL"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQaGaW-oFqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a344c9-5a43-4b34-a4c8-8b3dc0582e43"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La06XiW7oZSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640a956a-e11b-4663-b6e1-6c4011ac66da"
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " airline.csv\t        cal_housing.data\t\t      diabetes.csv\n",
            " bank.csv\t        cal_housing.domain\t\t      heart.csv\n",
            " boston_data.csv       'Colab Notebooks'\n",
            " boston_test_data.csv   Copy_of_Introduction_to_Spark.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYPpfuPeot6Q"
      },
      "source": [
        "# Import SparkSession from pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create spark_session\n",
        "spark_session = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60n66k2epA-d"
      },
      "source": [
        "df = spark_session.read.option(\"header\", \"true\").csv(\"/content/drive/My Drive/heart.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MrvUeVApVqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46289ba9-8f0c-452a-b181-8185ef097513"
      },
      "source": [
        "df.show()\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
            "| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|\n",
            "| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|\n",
            "| 57|  1|  0|     140| 192|  0|      1|    148|    0|    0.4|    1|  0|   1|     1|\n",
            "| 56|  0|  1|     140| 294|  0|      0|    153|    0|    1.3|    1|  0|   2|     1|\n",
            "| 44|  1|  1|     120| 263|  0|      1|    173|    0|      0|    2|  0|   3|     1|\n",
            "| 52|  1|  2|     172| 199|  1|      1|    162|    0|    0.5|    2|  0|   3|     1|\n",
            "| 57|  1|  2|     150| 168|  0|      1|    174|    0|    1.6|    2|  0|   2|     1|\n",
            "| 54|  1|  0|     140| 239|  0|      1|    160|    0|    1.2|    2|  0|   2|     1|\n",
            "| 48|  0|  2|     130| 275|  0|      1|    139|    0|    0.2|    2|  0|   2|     1|\n",
            "| 49|  1|  1|     130| 266|  0|      1|    171|    0|    0.6|    2|  0|   2|     1|\n",
            "| 64|  1|  3|     110| 211|  0|      0|    144|    1|    1.8|    1|  0|   2|     1|\n",
            "| 58|  0|  3|     150| 283|  1|      0|    162|    0|      1|    2|  0|   2|     1|\n",
            "| 50|  0|  2|     120| 219|  0|      1|    158|    0|    1.6|    1|  0|   2|     1|\n",
            "| 58|  0|  2|     120| 340|  0|      1|    172|    0|      0|    2|  0|   2|     1|\n",
            "| 66|  0|  3|     150| 226|  0|      1|    114|    0|    2.6|    0|  0|   2|     1|\n",
            "| 43|  1|  0|     150| 247|  0|      1|    171|    0|    1.5|    2|  0|   2|     1|\n",
            "| 69|  0|  3|     140| 239|  0|      1|    151|    0|    1.8|    2|  2|   2|     1|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 'string'),\n",
              " ('sex', 'string'),\n",
              " ('cp', 'string'),\n",
              " ('trestbps', 'string'),\n",
              " ('chol', 'string'),\n",
              " ('fbs', 'string'),\n",
              " ('restecg', 'string'),\n",
              " ('thalach', 'string'),\n",
              " ('exang', 'string'),\n",
              " ('oldpeak', 'string'),\n",
              " ('slope', 'string'),\n",
              " ('ca', 'string'),\n",
              " ('thal', 'string'),\n",
              " ('target', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjL6VLicu6mj"
      },
      "source": [
        "df.createOrReplaceTempView(\"heart\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4s_ApgRu-fN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23011961-b434-46ed-de42-543177e16ad8"
      },
      "source": [
        "modeldata = spark_session.sql(\"SELECT * FROM heart\")\n",
        "modeldata.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
            "| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|\n",
            "| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|\n",
            "| 57|  1|  0|     140| 192|  0|      1|    148|    0|    0.4|    1|  0|   1|     1|\n",
            "| 56|  0|  1|     140| 294|  0|      0|    153|    0|    1.3|    1|  0|   2|     1|\n",
            "| 44|  1|  1|     120| 263|  0|      1|    173|    0|      0|    2|  0|   3|     1|\n",
            "| 52|  1|  2|     172| 199|  1|      1|    162|    0|    0.5|    2|  0|   3|     1|\n",
            "| 57|  1|  2|     150| 168|  0|      1|    174|    0|    1.6|    2|  0|   2|     1|\n",
            "| 54|  1|  0|     140| 239|  0|      1|    160|    0|    1.2|    2|  0|   2|     1|\n",
            "| 48|  0|  2|     130| 275|  0|      1|    139|    0|    0.2|    2|  0|   2|     1|\n",
            "| 49|  1|  1|     130| 266|  0|      1|    171|    0|    0.6|    2|  0|   2|     1|\n",
            "| 64|  1|  3|     110| 211|  0|      0|    144|    1|    1.8|    1|  0|   2|     1|\n",
            "| 58|  0|  3|     150| 283|  1|      0|    162|    0|      1|    2|  0|   2|     1|\n",
            "| 50|  0|  2|     120| 219|  0|      1|    158|    0|    1.6|    1|  0|   2|     1|\n",
            "| 58|  0|  2|     120| 340|  0|      1|    172|    0|      0|    2|  0|   2|     1|\n",
            "| 66|  0|  3|     150| 226|  0|      1|    114|    0|    2.6|    0|  0|   2|     1|\n",
            "| 43|  1|  0|     150| 247|  0|      1|    171|    0|    1.5|    2|  0|   2|     1|\n",
            "| 69|  0|  3|     140| 239|  0|      1|    151|    0|    1.8|    2|  2|   2|     1|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Si3lEirsWR"
      },
      "source": [
        "Cast the columns into appropriate data types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHg_8auisEyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4899f223-d9d1-4713-ad2f-62043c2eda3a"
      },
      "source": [
        "# Cast the columns to an appropriate data type\n",
        "modeldata = modeldata.withColumn(\"age\", modeldata.age.cast(\"integer\"))\n",
        "modeldata = modeldata.withColumn(\"trestbps\", modeldata.trestbps.cast(\"integer\"))\n",
        "modeldata = modeldata.withColumn(\"chol\", modeldata.chol.cast(\"integer\"))\n",
        "modeldata = modeldata.withColumn(\"thalach\", modeldata.thalach.cast(\"integer\"))\n",
        "modeldata = modeldata.withColumn(\"oldpeak\", modeldata.oldpeak.cast(\"float\"))\n",
        "modeldata = modeldata.withColumn(\"target\", modeldata.target.cast(\"integer\"))\n",
        "\n",
        "modeldata.show()\n",
        "modeldata.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
            "| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|\n",
            "| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|\n",
            "| 57|  1|  0|     140| 192|  0|      1|    148|    0|    0.4|    1|  0|   1|     1|\n",
            "| 56|  0|  1|     140| 294|  0|      0|    153|    0|    1.3|    1|  0|   2|     1|\n",
            "| 44|  1|  1|     120| 263|  0|      1|    173|    0|    0.0|    2|  0|   3|     1|\n",
            "| 52|  1|  2|     172| 199|  1|      1|    162|    0|    0.5|    2|  0|   3|     1|\n",
            "| 57|  1|  2|     150| 168|  0|      1|    174|    0|    1.6|    2|  0|   2|     1|\n",
            "| 54|  1|  0|     140| 239|  0|      1|    160|    0|    1.2|    2|  0|   2|     1|\n",
            "| 48|  0|  2|     130| 275|  0|      1|    139|    0|    0.2|    2|  0|   2|     1|\n",
            "| 49|  1|  1|     130| 266|  0|      1|    171|    0|    0.6|    2|  0|   2|     1|\n",
            "| 64|  1|  3|     110| 211|  0|      0|    144|    1|    1.8|    1|  0|   2|     1|\n",
            "| 58|  0|  3|     150| 283|  1|      0|    162|    0|    1.0|    2|  0|   2|     1|\n",
            "| 50|  0|  2|     120| 219|  0|      1|    158|    0|    1.6|    1|  0|   2|     1|\n",
            "| 58|  0|  2|     120| 340|  0|      1|    172|    0|    0.0|    2|  0|   2|     1|\n",
            "| 66|  0|  3|     150| 226|  0|      1|    114|    0|    2.6|    0|  0|   2|     1|\n",
            "| 43|  1|  0|     150| 247|  0|      1|    171|    0|    1.5|    2|  0|   2|     1|\n",
            "| 69|  0|  3|     140| 239|  0|      1|    151|    0|    1.8|    2|  2|   2|     1|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 'int'),\n",
              " ('sex', 'string'),\n",
              " ('cp', 'string'),\n",
              " ('trestbps', 'int'),\n",
              " ('chol', 'int'),\n",
              " ('fbs', 'string'),\n",
              " ('restecg', 'string'),\n",
              " ('thalach', 'int'),\n",
              " ('exang', 'string'),\n",
              " ('oldpeak', 'float'),\n",
              " ('slope', 'string'),\n",
              " ('ca', 'string'),\n",
              " ('thal', 'string'),\n",
              " ('target', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU7O1-0Vv10U"
      },
      "source": [
        "Examine the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2SOZY0v4J9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045c3036-1855-4da5-930a-7ee12d81d582"
      },
      "source": [
        "modeldata.describe().select('summary','age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+-------------------+------------------+------------------+------------------+-------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
            "|summary|               age|                sex|                cp|          trestbps|              chol|                fbs|          restecg|           thalach|              exang|           oldpeak|             slope|                ca|              thal|\n",
            "+-------+------------------+-------------------+------------------+------------------+------------------+-------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
            "|  count|               303|                303|               303|               303|               303|                303|              303|               303|                303|               303|               303|               303|               303|\n",
            "|   mean|54.366336633663366| 0.6831683168316832| 0.966996699669967|131.62376237623764|246.26402640264027| 0.1485148514851485|0.528052805280528|149.64686468646866|0.32673267326732675|1.0396039587977302|1.3993399339933994|0.7293729372937293|2.3135313531353137|\n",
            "| stddev|  9.08210098983786|0.46601082333962385|1.0320524894832983|  17.5381428135171| 51.83075098793005|0.35619787492797644|0.525859596359298| 22.90516111491409|0.46979446452231655|1.1610750102689427|0.6162261453459622|1.0226063649693276|0.6122765072781408|\n",
            "|    min|                29|                  0|                 0|                94|               126|                  0|                0|                71|                  0|               0.0|                 0|                 0|                 0|\n",
            "|    max|                77|                  1|                 3|               200|               564|                  1|                2|               202|                  1|               6.2|                 2|                 4|                 3|\n",
            "+-------+------------------+-------------------+------------------+------------------+------------------+-------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOopXZ8L0oPt"
      },
      "source": [
        "Use \"StringIndexer\" and \"OneHotEncoding\" to convert categorical features into numeric values. Combine all of the columns containing our features for the model into a single column - \"target\" is the label that the model will predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Uz2OvQ0pcc"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "#Store all the categorical columns\n",
        "categorical_Cols = ['sex','cp','fbs','restecg','exang','slope','ca','thal']\n",
        "pipeline_stages = []\n",
        "\n",
        "#Iterate through the categorical columns\n",
        "for categoricalCol in categorical_Cols:\n",
        "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + '_Index')\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"_conv\"])\n",
        "    pipeline_stages += [stringIndexer, encoder]\n",
        "\n",
        "#Store all the numeric columns\n",
        "numericCols = ['age','trestbps','chol','thalach','oldpeak']\n",
        "\n",
        "#Combine all of the columns containing our features for the model into a single column\n",
        "assembler_Inputs = [c + \"_conv\" for c in categorical_Cols] + numericCols\n",
        "assembler = VectorAssembler(inputCols=assembler_Inputs, outputCol=\"features\")\n",
        "pipeline_stages += [assembler]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcrazerQzjRH"
      },
      "source": [
        "# Create label column\n",
        "from pyspark.sql.functions import *\n",
        "modeldata = modeldata.withColumn(\"label\", col(\"target\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxfFomfSmBI9"
      },
      "source": [
        "We use the ML Pipeline to chain multiple Transformers and Estimators together to screate the machine learning workflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_-KVqiemHXC",
        "outputId": "eb7522ca-4106-428d-8291-3fce5364d4db"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "ml_pipe = Pipeline(stages = pipeline_stages)\n",
        "# Fit and transform the data\n",
        "pipe_data = ml_pipe.fit(modeldata).transform(modeldata)\n",
        "selectedCols = ['label','features','age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','target']\n",
        "modeldata = pipe_data.select(selectedCols)\n",
        "modeldata.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|label|            features|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+-----+--------------------+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|    1|(22,[0,6,7,10,16,...| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "|    1|(22,[0,2,4,5,7,10...| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "|    1|(22,[3,4,6,7,8,10...| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
            "|    1|(22,[0,3,4,5,7,8,...| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|\n",
            "|    1|(22,[1,4,5,8,10,1...| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|\n",
            "|    1|(22,[0,1,4,5,7,9,...| 57|  1|  0|     140| 192|  0|      1|    148|    0|    0.4|    1|  0|   1|     1|\n",
            "|    1|(22,[3,4,6,7,9,10...| 56|  0|  1|     140| 294|  0|      0|    153|    0|    1.3|    1|  0|   2|     1|\n",
            "|    1|(22,[0,3,4,5,7,8,...| 44|  1|  1|     120| 263|  0|      1|    173|    0|    0.0|    2|  0|   3|     1|\n",
            "|    1|(22,[0,2,5,7,8,10...| 52|  1|  2|     172| 199|  1|      1|    162|    0|    0.5|    2|  0|   3|     1|\n",
            "|    1|(22,[0,2,4,5,7,8,...| 57|  1|  2|     150| 168|  0|      1|    174|    0|    1.6|    2|  0|   2|     1|\n",
            "|    1|(22,[0,1,4,5,7,8,...| 54|  1|  0|     140| 239|  0|      1|    160|    0|    1.2|    2|  0|   2|     1|\n",
            "|    1|(22,[2,4,5,7,8,10...| 48|  0|  2|     130| 275|  0|      1|    139|    0|    0.2|    2|  0|   2|     1|\n",
            "|    1|(22,[0,3,4,5,7,8,...| 49|  1|  1|     130| 266|  0|      1|    171|    0|    0.6|    2|  0|   2|     1|\n",
            "|    1|(22,[0,4,6,9,10,1...| 64|  1|  3|     110| 211|  0|      0|    144|    1|    1.8|    1|  0|   2|     1|\n",
            "|    1|(22,[6,7,8,10,14,...| 58|  0|  3|     150| 283|  1|      0|    162|    0|    1.0|    2|  0|   2|     1|\n",
            "|    1|(22,[2,4,5,7,9,10...| 50|  0|  2|     120| 219|  0|      1|    158|    0|    1.6|    1|  0|   2|     1|\n",
            "|    1|(22,[2,4,5,7,8,10...| 58|  0|  2|     120| 340|  0|      1|    172|    0|    0.0|    2|  0|   2|     1|\n",
            "|    1|(22,[4,5,7,10,14,...| 66|  0|  3|     150| 226|  0|      1|    114|    0|    2.6|    0|  0|   2|     1|\n",
            "|    1|(22,[0,1,4,5,7,8,...| 43|  1|  0|     150| 247|  0|      1|    171|    0|    1.5|    2|  0|   2|     1|\n",
            "|    1|(22,[4,5,7,8,12,1...| 69|  0|  3|     140| 239|  0|      1|    151|    0|    1.8|    2|  2|   2|     1|\n",
            "+-----+--------------------+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-877ASlGzua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9351fed-894c-4f74-f652-cf1e290d1b38"
      },
      "source": [
        "train, test = modeldata.randomSplit([0.8, 0.2], seed=12345)\n",
        "train.show(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|label|            features|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+-----+--------------------+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|    0|(22,[0,1,4,5,7,8,...| 40|  1|  0|     152| 223|  0|      1|    181|    0|    0.0|    2|  0|   3|     0|\n",
            "|    0|(22,[0,1,4,5,7,8,...| 52|  1|  0|     112| 230|  0|      1|    160|    0|    0.0|    2|  1|   2|     0|\n",
            "|    0|(22,[0,1,4,5,7,8,...| 61|  1|  0|     148| 203|  0|      1|    161|    0|    0.0|    2|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,7,8,...| 58|  1|  0|     100| 234|  0|      1|    156|    0|    0.1|    2|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,7,8,...| 52|  1|  0|     125| 212|  0|      1|    168|    0|    1.0|    2|  2|   3|     0|\n",
            "|    0|(22,[0,1,4,5,7,9,...| 67|  1|  0|     120| 237|  0|      1|     71|    0|    1.0|    1|  0|   2|     0|\n",
            "|    0|(22,[0,1,4,5,7,9,...| 54|  1|  0|     120| 188|  0|      1|    113|    0|    1.4|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,7,9,...| 58|  1|  0|     146| 218|  0|      1|    105|    0|    2.0|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,8,10...| 51|  1|  0|     140| 299|  0|      1|    173|    1|    1.6|    2|  0|   3|     0|\n",
            "|    0|(22,[0,1,4,5,8,11...| 52|  1|  0|     128| 255|  0|      1|    161|    1|    0.0|    2|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,8,11...| 59|  1|  0|     140| 177|  0|      1|    162|    1|    0.0|    2|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,8,11...| 60|  1|  0|     130| 253|  0|      1|    144|    1|    1.4|    2|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,10...| 35|  1|  0|     120| 198|  0|      1|    130|    1|    1.6|    1|  0|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,10...| 42|  1|  0|     136| 315|  0|      1|    125|    1|    1.8|    1|  0|   1|     0|\n",
            "|    0|(22,[0,1,4,5,9,11...| 54|  1|  0|     110| 239|  0|      1|    126|    1|    2.8|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,11...| 55|  1|  0|     132| 353|  0|      1|    132|    1|    1.2|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,11...| 57|  1|  0|     110| 335|  0|      1|    143|    1|    3.0|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,11...| 57|  1|  0|     130| 131|  0|      1|    115|    1|    1.2|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,11...| 57|  1|  0|     152| 274|  0|      1|     88|    1|    1.2|    1|  1|   3|     0|\n",
            "|    0|(22,[0,1,4,5,9,11...| 61|  1|  0|     120| 260|  0|      1|    140|    1|    3.6|    1|  1|   3|     0|\n",
            "+-----+--------------------+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ453u8wZ07n"
      },
      "source": [
        "After the train/test split, it is a good practice to check if there is a imbalance in the train dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-bADGkeJeXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb4ed8e-9c71-4e01-82d8-13e6a3e61dc5"
      },
      "source": [
        "size_of_dataset = float(train.select(\"target\").count())\n",
        "no_of_Positives = train.select(\"target\").where('target == 1').count()\n",
        "percent_ones=(float(no_of_Positives)/float(size_of_dataset))*100\n",
        "no_of_Negatives=float(size_of_dataset - no_of_Positives)\n",
        "print('The number of ones are {}'.format(no_of_Positives))\n",
        "print('Percentage of ones are {}'.format(percent_ones))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of ones are 134\n",
            "Percentage of ones are 53.17460317460318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odEVf09Qba7C"
      },
      "source": [
        "Conclusion: The training dataset is quite evenly balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI8qaB93e4pX"
      },
      "source": [
        "**Selecting Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZYtVq46gp29"
      },
      "source": [
        "The underlying data set has several features; however, \n",
        "some of these features are more signifcant as compared to others. Therefrore, we will leverage the \"ChiSqSelector\" class provided by Spark ML for selecting the significant features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE99nszpfLMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f289b6-c080-44b1-c915-8d56a280c958"
      },
      "source": [
        "from pyspark.ml.feature import ChiSqSelector\n",
        "\n",
        "selector = ChiSqSelector(featuresCol='features',outputCol='Significant_feat',labelCol='target',fpr=0.05)\n",
        "train=selector.fit(train).transform(train)\n",
        "test=selector.fit(test).transform(test)\n",
        "test.select(\"Significant_feat\").show(20,truncate=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------+\n",
            "|Significant_feat                                                                                                   |\n",
            "+-------------------------------------------------------------------------------------------------------------------+\n",
            "|(22,[0,1,4,5,7,9,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,39.0,118.0,219.0,140.0,1.2000000476837158])|\n",
            "|(22,[0,1,4,5,9,13,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,51.0,140.0,298.0,122.0,4.199999809265137])       |\n",
            "|(22,[0,1,4,5,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,55.0,140.0,217.0,111.0,5.599999904632568])             |\n",
            "|(22,[0,1,4,6,7,8,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,46.0,120.0,249.0,144.0,0.800000011920929]) |\n",
            "|(22,[0,1,4,6,7,9,11,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,63.0,130.0,254.0,147.0,1.399999976158142]) |\n",
            "|(22,[0,1,4,6,9,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,40.0,110.0,167.0,114.0,2.0])                     |\n",
            "|(22,[0,1,4,6,9,11,14,17,18,19,20],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,54.0,110.0,206.0,108.0])                            |\n",
            "|(22,[0,1,4,6,9,13,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,58.0,128.0,216.0,131.0,2.200000047683716])       |\n",
            "|(22,[0,2,4,6,7,9,10,14,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,60.0,140.0,185.0,155.0,3.0])               |\n",
            "|(22,[0,2,4,6,7,9,11,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,58.0,112.0,230.0,165.0,2.5])               |\n",
            "|(22,[0,2,6,9,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,68.0,180.0,274.0,150.0,1.600000023841858])             |\n",
            "|(22,[0,4,6,7,9,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,59.0,170.0,288.0,159.0,0.20000000298023224])     |\n",
            "|(22,[1,4,5,9,10,14,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,62.0,150.0,244.0,154.0,1.399999976158142])             |\n",
            "|(22,[1,4,5,9,12,14,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,63.0,108.0,269.0,169.0,1.7999999523162842])            |\n",
            "|(22,[1,4,6,7,9,13,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,63.0,150.0,407.0,154.0,4.0])                     |\n",
            "|(22,[1,4,6,7,12,14,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,62.0,140.0,268.0,160.0,3.5999999046325684])            |\n",
            "|(22,[1,4,6,9,10,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,61.0,145.0,307.0,146.0,1.0])                           |\n",
            "|(22,[1,4,9,11,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,55.0,128.0,205.0,130.0,2.0])                                 |\n",
            "|(22,[1,6,9,12,16,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,58.0,170.0,225.0,146.0,2.799999952316284])                   |\n",
            "|(22,[2,4,5,7,9,11,15,17,18,19,20,21],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,62.0,130.0,263.0,97.0,1.2000000476837158])       |\n",
            "+-------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ic1v5QyzEJ"
      },
      "source": [
        "**Creating the Logistic Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnEZsgVViTJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b83baa5-a8a9-4d8c-b338-cc10040d4db8"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "logit_regression = LogisticRegression(labelCol=\"target\", featuresCol=\"Significant_feat\",maxIter=25)\n",
        "model=logit_regression.fit(train)\n",
        "prediction_on_train_dataset=model.transform(train)\n",
        "prediction_on_test_dataset=model.transform(test)\n",
        "prediction_on_test_dataset.select(\"target\",\"rawPrediction\",\"probability\",\"prediction\").show(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+--------------------+----------+\n",
            "|target|       rawPrediction|         probability|prediction|\n",
            "+------+--------------------+--------------------+----------+\n",
            "|     0|[1.80277928936483...|[0.85848691951327...|       0.0|\n",
            "|     0|[6.95022734344597...|[0.99904250044503...|       0.0|\n",
            "|     0|[4.68485906921245...|[0.99085045137976...|       0.0|\n",
            "|     0|[0.83428759431574...|[0.69726075510254...|       0.0|\n",
            "|     0|[4.63608711464237...|[0.99039754011609...|       0.0|\n",
            "|     0|[2.52752726516890...|[0.92604919365878...|       0.0|\n",
            "|     0|[3.18982857338739...|[0.96044970914051...|       0.0|\n",
            "|     0|[4.66065232875761...|[0.99062836916790...|       0.0|\n",
            "|     0|[-1.6602202781472...|[0.15973242943953...|       1.0|\n",
            "|     0|[1.98692673656585...|[0.87941762153031...|       0.0|\n",
            "|     0|[1.20507209909940...|[0.76942585255753...|       0.0|\n",
            "|     0|[1.00255542261577...|[0.73156070845377...|       0.0|\n",
            "|     0|[-1.4965112109885...|[0.18294644093137...|       1.0|\n",
            "|     0|[0.97509125452855...|[0.72613312885830...|       0.0|\n",
            "|     0|[5.43917668013199...|[0.99567572305880...|       0.0|\n",
            "|     0|[3.08992999009337...|[0.95647545061404...|       0.0|\n",
            "|     0|[1.24944839167698...|[0.77720436052798...|       0.0|\n",
            "|     0|[4.15045544975502...|[0.98448720065472...|       0.0|\n",
            "|     0|[2.97023304532353...|[0.95121109343388...|       0.0|\n",
            "|     0|[2.06974374614091...|[0.88792746357129...|       0.0|\n",
            "|     1|[-2.1089013717223...|[0.10823466064334...|       1.0|\n",
            "|     1|[0.33419027865668...|[0.58277858552064...|       0.0|\n",
            "|     1|[-4.0677966581334...|[0.01682706119906...|       1.0|\n",
            "|     1|[0.78179928964768...|[0.68606777243427...|       0.0|\n",
            "|     1|[0.67181040003458...|[0.66190841945506...|       0.0|\n",
            "|     1|[-1.6589101279029...|[0.15990835356148...|       1.0|\n",
            "|     1|[-0.1507245052346...|[0.46239004826659...|       1.0|\n",
            "|     1|[-4.6054471218406...|[0.00989827567622...|       1.0|\n",
            "|     1|[-2.1185846847650...|[0.10730356751167...|       1.0|\n",
            "|     1|[-2.5374668384724...|[0.07327299956219...|       1.0|\n",
            "+------+--------------------+--------------------+----------+\n",
            "only showing top 30 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw-g4S3g3ift"
      },
      "source": [
        "**Evaluating the Model** - Since the Logistic model at hand is a binary classification model (given that the outcome is 1 or 0), the BinaryClassificationEvaluator from the ***pyspark.ml.evaluation*** module will be utilized to evaluate the Logistic Regression Model.\n",
        "\n",
        "The BinaryClassificationEvaluator calculates the area under the ROC which is is one of the most important evaluation metrics for checking any classification model’s performance. It finds the best model by maximizing the model evaluation metric that is the area under the specified curve. The closer the area Under Curve is to one (1), the better the model is!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcQ3Hnnr3lTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6140c178-da3c-4263-fa38-1a8e9768be54"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"target\",metricName=\"areaUnderROC\")\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(\"The area under ROC for test data set is {}\".format(evaluator.evaluate(prediction_on_test_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The area under ROC for test data set is 0.896774193548387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv-Z6i7w5Xkk"
      },
      "source": [
        "**The area under ROC is quite large, therefore, it can be concluded that the model generated is good in predicting the onset of heart disease.**"
      ]
    }
  ]
}
